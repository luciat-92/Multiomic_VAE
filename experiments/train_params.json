{"batch_size": 64, 
"lr": 0.0001, 
"pretrain_num_epochs": 500,
"train_num_epochs": 1000, 
"alpha": 1.0, 
"classifier_hidden_dims": [64, 32],  
"encoder_hidden_dims": [512, 256],
"latent_dim": 128, 
"dop": 0.0, 
"retrain_flag": true, 
"es_flag": false, 
"norm_flag": true}